{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config, get_config\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import tools\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "from mlxtend.evaluate.time_series import GroupTimeSeriesSplit, plot_splits, print_cv_info, print_split_info\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import warnings; warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train = pd.read_csv('./data/kaggle/train.csv')\n",
    "new_train = pd.read_csv('./data/kaggle/revealed_test.csv')\n",
    "\n",
    "old_test = pd.read_csv('./data/kaggle/test.csv')\n",
    "sample_submission = pd.read_csv('./data/kaggle/sample_submission.csv')\n",
    "\n",
    "train = pd.concat((old_train, new_train))\n",
    "test = old_test[~old_test['first_day_of_month'].isin(new_train['first_day_of_month'])]\n",
    "\n",
    "train['is_test'] = 0 ; test['is_test'] = 1\n",
    "\n",
    "data = pd.concat((\n",
    "        train,\n",
    "        test)\n",
    "        )\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .assign(\n",
    "        cfips = lambda df: df['cfips'].astype(str).str.zfill(5),\n",
    "        date = lambda df: pd.to_datetime(df[\"first_day_of_month\"]),\n",
    "        mdensity_t0 = lambda df: df['microbusiness_density'],\n",
    "        active_t0 = lambda df: df['active'],\n",
    "        )\\\n",
    "    .sort_values(['cfips','date'], ascending=True)\\\n",
    "    .assign(\n",
    "    \n",
    "        state_i = lambda df: df['cfips'].apply(lambda x: x[:2]),\n",
    "        county_i = lambda df: df['cfips'].apply(lambda x: x[2:]),\n",
    "        \n",
    "        year = lambda df: df['date'].dt.year,\n",
    "        date = lambda df: df[\"date\"].dt.date,\n",
    "        # month = lambda df: df['date'].dt.month,\n",
    "\n",
    "        dcount = lambda df: df.groupby('cfips')['row_id'].cumcount(),\n",
    "        \n",
    "        active_lag1 = lambda df: df.groupby('cfips')['active_t0'].shift(1),\n",
    "        active_lag2 = lambda df: df.groupby('cfips')['active_t0'].shift(2),\n",
    "        active_lag3 = lambda df: df.groupby('cfips')['active_t0'].shift(3),\n",
    "        active_lag4 = lambda df: df.groupby('cfips')['active_t0'].shift(4),\n",
    "        active_lag5 = lambda df: df.groupby('cfips')['active_t0'].shift(5),\n",
    "        active_lag6 = lambda df: df.groupby('cfips')['active_t0'].shift(6),\n",
    "        \n",
    "        target_0 = lambda df: np.nan_to_num(df['active']/df['active_lag1']),\n",
    "        target_1 = lambda df: np.nan_to_num(df['active']/df['active_lag2']),\n",
    "        target_2 = lambda df: np.nan_to_num(df['active']/df['active_lag3']),\n",
    "        # target_1 = lambda df: np.nan_to_num(df['active']),\n",
    "        # target_2 = lambda df: np.nan_to_num(df['active']),\n",
    "\n",
    "    \n",
    "\n",
    "    )\\\n",
    "    .drop(['county','state'], axis='columns')\n",
    "# .sort_index(ascending=True)\n",
    "\n",
    "assert all(data.groupby('cfips')['county_i'].nunique() == 1)\n",
    "assert all(data.groupby('cfips')['state_i'].nunique() == 1)\n",
    "assert data['cfips'].nunique() == 3135 # there are 3135 county,state tuples\n",
    "assert data['dcount'].nunique() == 47 # there are 47 series for each county state tuple\n",
    "assert data.query('is_test==0')['dcount'].nunique() == 41 # there are 41 series in the train set. \n",
    "assert data.query('is_test==1')['dcount'].nunique() == 6  # there are 6 series in the test set. \n",
    "\n",
    "#The private leaderboard will include 03-2023, 04-2023, 05-2023\n",
    "#The public leaderboard includes the first month 11-2022. Probably it will be updated later as 12-2022,01-2023 and 02-2023\n",
    "#The LB is updated as 01-2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>is_test</th>\n",
       "      <th>date</th>\n",
       "      <th>mdensity_t0</th>\n",
       "      <th>active_t0</th>\n",
       "      <th>state_i</th>\n",
       "      <th>county_i</th>\n",
       "      <th>year</th>\n",
       "      <th>dcount</th>\n",
       "      <th>active_lag1</th>\n",
       "      <th>active_lag2</th>\n",
       "      <th>active_lag3</th>\n",
       "      <th>active_lag4</th>\n",
       "      <th>active_lag5</th>\n",
       "      <th>active_lag6</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134804</th>\n",
       "      <td>56045_2023-02-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>2023</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137939</th>\n",
       "      <td>56045_2023-03-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>2023</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141074</th>\n",
       "      <td>56045_2023-04-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>2023</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144209</th>\n",
       "      <td>56045_2023-05-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>2023</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147344</th>\n",
       "      <td>56045_2023-06-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>045</td>\n",
       "      <td>2023</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147345 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  row_id  cfips first_day_of_month  microbusiness_density  active  is_test        date  mdensity_t0  active_t0 state_i county_i  year  dcount  active_lag1  active_lag2  active_lag3  active_lag4  active_lag5  active_lag6  target_0  target_1  target_2\n",
       "0        1001_2019-08-01  01001         2019-08-01                   3.01 1249.00        0  2019-08-01         3.01    1249.00      01      001  2019       0          NaN          NaN          NaN          NaN          NaN          NaN      0.00      0.00      0.00\n",
       "1        1001_2019-09-01  01001         2019-09-01                   2.88 1198.00        0  2019-09-01         2.88    1198.00      01      001  2019       1      1249.00          NaN          NaN          NaN          NaN          NaN      0.96      0.00      0.00\n",
       "2        1001_2019-10-01  01001         2019-10-01                   3.06 1269.00        0  2019-10-01         3.06    1269.00      01      001  2019       2      1198.00      1249.00          NaN          NaN          NaN          NaN      1.06      1.02      0.00\n",
       "3        1001_2019-11-01  01001         2019-11-01                   2.99 1243.00        0  2019-11-01         2.99    1243.00      01      001  2019       3      1269.00      1198.00      1249.00          NaN          NaN          NaN      0.98      1.04      1.00\n",
       "4        1001_2019-12-01  01001         2019-12-01                   2.99 1243.00        0  2019-12-01         2.99    1243.00      01      001  2019       4      1243.00      1269.00      1198.00      1249.00          NaN          NaN      1.00      0.98      1.04\n",
       "...                  ...    ...                ...                    ...     ...      ...         ...          ...        ...     ...      ...   ...     ...          ...          ...          ...          ...          ...          ...       ...       ...       ...\n",
       "134804  56045_2023-02-01  56045         2023-02-01                    NaN     NaN        1  2023-02-01          NaN        NaN      56      045  2023      42          NaN       101.00       100.00       100.00       100.00       100.00      0.00      0.00      0.00\n",
       "137939  56045_2023-03-01  56045         2023-03-01                    NaN     NaN        1  2023-03-01          NaN        NaN      56      045  2023      43          NaN          NaN       101.00       100.00       100.00       100.00      0.00      0.00      0.00\n",
       "141074  56045_2023-04-01  56045         2023-04-01                    NaN     NaN        1  2023-04-01          NaN        NaN      56      045  2023      44          NaN          NaN          NaN       101.00       100.00       100.00      0.00      0.00      0.00\n",
       "144209  56045_2023-05-01  56045         2023-05-01                    NaN     NaN        1  2023-05-01          NaN        NaN      56      045  2023      45          NaN          NaN          NaN          NaN       101.00       100.00      0.00      0.00      0.00\n",
       "147344  56045_2023-06-01  56045         2023-06-01                    NaN     NaN        1  2023-06-01          NaN        NaN      56      045  2023      46          NaN          NaN          NaN          NaN          NaN       101.00      0.00      0.00      0.00\n",
       "\n",
       "[147345 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding census data\n",
    "data_census = []\n",
    "for year in range(2017,2022):\n",
    "    COLS = ['GEO_ID','NAME','S0101_C01_026E']\n",
    "    data_census_i = pd.read_csv(f'./data/census/ACSST5Y{year}.S0101-Data.csv',usecols=COLS)\n",
    "    data_census_i = data_census_i.iloc[1:]\n",
    "    data_census_i['population'] = data_census_i['S0101_C01_026E'].astype('int')\n",
    "\n",
    "\n",
    "    data_census_i['cfips'] = data_census_i.GEO_ID.apply(lambda x: f\"{int(x.split('US')[-1]):05}\" )\n",
    "    data_census_i['year'] = year+2\n",
    "    data_census.append(data_census_i[['cfips','year','population']])\n",
    "\n",
    "data_census = pd.concat((data_census),axis='rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(data_census, on=['cfips','year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>is_test</th>\n",
       "      <th>date</th>\n",
       "      <th>mdensity_t0</th>\n",
       "      <th>active_t0</th>\n",
       "      <th>state_i</th>\n",
       "      <th>county_i</th>\n",
       "      <th>year</th>\n",
       "      <th>dcount</th>\n",
       "      <th>active_lag1</th>\n",
       "      <th>active_lag2</th>\n",
       "      <th>active_lag3</th>\n",
       "      <th>active_lag4</th>\n",
       "      <th>active_lag5</th>\n",
       "      <th>active_lag6</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>41527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1243.00</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>1249.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.04</td>\n",
       "      <td>41527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips first_day_of_month  microbusiness_density  active  is_test        date  mdensity_t0  active_t0 state_i county_i  year  dcount  active_lag1  active_lag2  active_lag3  active_lag4  active_lag5  active_lag6  target_0  target_1  target_2  population\n",
       "0  1001_2019-08-01  01001         2019-08-01                   3.01 1249.00        0  2019-08-01         3.01    1249.00      01      001  2019       0          NaN          NaN          NaN          NaN          NaN          NaN      0.00      0.00      0.00       41527\n",
       "1  1001_2019-09-01  01001         2019-09-01                   2.88 1198.00        0  2019-09-01         2.88    1198.00      01      001  2019       1      1249.00          NaN          NaN          NaN          NaN          NaN      0.96      0.00      0.00       41527\n",
       "2  1001_2019-10-01  01001         2019-10-01                   3.06 1269.00        0  2019-10-01         3.06    1269.00      01      001  2019       2      1198.00      1249.00          NaN          NaN          NaN          NaN      1.06      1.02      0.00       41527\n",
       "3  1001_2019-11-01  01001         2019-11-01                   2.99 1243.00        0  2019-11-01         2.99    1243.00      01      001  2019       3      1269.00      1198.00      1249.00          NaN          NaN          NaN      0.98      1.04      1.00       41527\n",
       "4  1001_2019-12-01  01001         2019-12-01                   2.99 1243.00        0  2019-12-01         2.99    1243.00      01      001  2019       4      1243.00      1269.00      1198.00      1249.00          NaN          NaN      1.00      0.98      1.04       41527"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "n_SPLITS = 5 \n",
    "n_TRAIN_TRAIN_SIZE = 6\n",
    "n_TRAIN_PERIOD = n_TRAIN_TRAIN_SIZE + 3 + n_SPLITS - 1 \n",
    "\n",
    "\n",
    "TEST_DATES = list(np.sort(data.query('is_test==1')['date'].unique())[:3])\n",
    "TEST_PERIOD = list(np.sort(data.query('is_test==1')['dcount'].unique())[:3])\n",
    "\n",
    "TRAIN_PERIOD = list(np.sort(data.query('is_test==0')['dcount'].unique())[-n_TRAIN_PERIOD:])\n",
    "TRAIN_DATES = list(np.sort(data.query('is_test==0')['date'].unique())[-n_TRAIN_PERIOD:])\n",
    "\n",
    "LEAKAGE = ['mdensity_t0','active_t0']\n",
    "TARGETS = ['target_0', 'target_1', 'target_2']\n",
    "FEATURES = ['population']\n",
    "LAG_TARGET = ['active_lag1', 'active_lag2', 'active_lag3','active_lag4','active_lag5','active_lag6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['dcount'].isin(TEST_PERIOD)].head()\n",
    "# sample = data[data.cfips.isin(['01001'])] # sample = data[data.cfips.isin(['01001','56045'])]\n",
    "sample = data.copy()\n",
    "sample.loc[sample.is_test==1,TARGETS]  = np.nan\n",
    "sample = sample.set_index(['date','cfips']).sort_index().loc[TRAIN_DATES+TEST_DATES]\n",
    "sample = sample[['dcount','county_i'] + LAG_TARGET + TARGETS + FEATURES+ LEAKAGE]\n",
    "sample_train= sample.query(\"dcount in @TRAIN_PERIOD\") ; sample_test= sample.query(\"dcount in @TEST_PERIOD\")\n",
    "train_X = sample_train.drop(TARGETS,axis='columns') ; train_y = sample_train[TARGETS]\n",
    "test_X = sample_test.drop(TARGETS,axis='columns') ; test_y = sample_test[TARGETS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dcount</th>\n",
       "      <th>county_i</th>\n",
       "      <th>active_lag1</th>\n",
       "      <th>active_lag2</th>\n",
       "      <th>active_lag3</th>\n",
       "      <th>active_lag4</th>\n",
       "      <th>active_lag5</th>\n",
       "      <th>active_lag6</th>\n",
       "      <th>population</th>\n",
       "      <th>mdensity_t0</th>\n",
       "      <th>active_t0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>cfips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-12-01</th>\n",
       "      <th>01001</th>\n",
       "      <td>28</td>\n",
       "      <td>001</td>\n",
       "      <td>1350.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1344.00</td>\n",
       "      <td>1358.00</td>\n",
       "      <td>1354.00</td>\n",
       "      <td>1359.00</td>\n",
       "      <td>42175</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1386.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>28</td>\n",
       "      <td>003</td>\n",
       "      <td>13162.00</td>\n",
       "      <td>13048.00</td>\n",
       "      <td>12998.00</td>\n",
       "      <td>13192.00</td>\n",
       "      <td>13301.00</td>\n",
       "      <td>13456.00</td>\n",
       "      <td>166595</td>\n",
       "      <td>7.93</td>\n",
       "      <td>13211.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>28</td>\n",
       "      <td>005</td>\n",
       "      <td>231.00</td>\n",
       "      <td>228.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>230.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>20054</td>\n",
       "      <td>1.15</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01007</th>\n",
       "      <td>28</td>\n",
       "      <td>007</td>\n",
       "      <td>220.00</td>\n",
       "      <td>212.00</td>\n",
       "      <td>212.00</td>\n",
       "      <td>216.00</td>\n",
       "      <td>221.00</td>\n",
       "      <td>221.00</td>\n",
       "      <td>17862</td>\n",
       "      <td>1.21</td>\n",
       "      <td>216.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01009</th>\n",
       "      <td>28</td>\n",
       "      <td>009</td>\n",
       "      <td>768.00</td>\n",
       "      <td>767.00</td>\n",
       "      <td>766.00</td>\n",
       "      <td>758.00</td>\n",
       "      <td>760.00</td>\n",
       "      <td>759.00</td>\n",
       "      <td>44292</td>\n",
       "      <td>1.75</td>\n",
       "      <td>776.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-12-01</th>\n",
       "      <th>56037</th>\n",
       "      <td>40</td>\n",
       "      <td>037</td>\n",
       "      <td>902.00</td>\n",
       "      <td>905.00</td>\n",
       "      <td>901.00</td>\n",
       "      <td>901.00</td>\n",
       "      <td>909.00</td>\n",
       "      <td>892.00</td>\n",
       "      <td>32049</td>\n",
       "      <td>2.88</td>\n",
       "      <td>922.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>40</td>\n",
       "      <td>039</td>\n",
       "      <td>5054.00</td>\n",
       "      <td>5035.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>4999.00</td>\n",
       "      <td>4971.00</td>\n",
       "      <td>4916.00</td>\n",
       "      <td>19164</td>\n",
       "      <td>26.31</td>\n",
       "      <td>5043.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>40</td>\n",
       "      <td>041</td>\n",
       "      <td>583.00</td>\n",
       "      <td>582.00</td>\n",
       "      <td>580.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>578.00</td>\n",
       "      <td>567.00</td>\n",
       "      <td>14516</td>\n",
       "      <td>4.05</td>\n",
       "      <td>588.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>40</td>\n",
       "      <td>043</td>\n",
       "      <td>190.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>194.00</td>\n",
       "      <td>194.00</td>\n",
       "      <td>195.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>6045</td>\n",
       "      <td>3.06</td>\n",
       "      <td>185.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>40</td>\n",
       "      <td>045</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>5601</td>\n",
       "      <td>1.80</td>\n",
       "      <td>101.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40755 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dcount county_i  active_lag1  active_lag2  active_lag3  active_lag4  active_lag5  active_lag6  population  mdensity_t0  active_t0\n",
       "date       cfips                                                                                                                                   \n",
       "2021-12-01 01001      28      001      1350.00      1351.00      1344.00      1358.00      1354.00      1359.00       42175         3.29    1386.00\n",
       "           01003      28      003     13162.00     13048.00     12998.00     13192.00     13301.00     13456.00      166595         7.93   13211.00\n",
       "           01005      28      005       231.00       228.00       225.00       232.00       230.00       222.00       20054         1.15     231.00\n",
       "           01007      28      007       220.00       212.00       212.00       216.00       221.00       221.00       17862         1.21     216.00\n",
       "           01009      28      009       768.00       767.00       766.00       758.00       760.00       759.00       44292         1.75     776.00\n",
       "...                  ...      ...          ...          ...          ...          ...          ...          ...         ...          ...        ...\n",
       "2022-12-01 56037      40      037       902.00       905.00       901.00       901.00       909.00       892.00       32049         2.88     922.00\n",
       "           56039      40      039      5054.00      5035.00      5000.00      4999.00      4971.00      4916.00       19164        26.31    5043.00\n",
       "           56041      40      041       583.00       582.00       580.00       577.00       578.00       567.00       14516         4.05     588.00\n",
       "           56043      40      043       190.00       189.00       194.00       194.00       195.00       189.00        6045         3.06     185.00\n",
       "           56045      40      045       100.00       100.00       100.00       100.00       101.00       101.00        5601         1.80     101.00\n",
       "\n",
       "[40755 rows x 11 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'n_iter': 200,\n",
    "    'verbosity': -1,\n",
    "    'objective': 'l1',\n",
    "    'random_state': 42,\n",
    "    'extra_trees': True,\n",
    "    'colsample_bytree': 0.88,\n",
    "    'colsample_bynode': 0.93,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.015,\n",
    "    'lambda_l1': 4.7,\n",
    "    'lambda_l2': 6.7,\n",
    "    'num_leaves': 541,\n",
    "    'min_data_in_leaf': 243\n",
    "    }\n",
    "\n",
    "\n",
    "# lgb_params = {\n",
    "#     'n_iter': 200,\n",
    "#     'verbosity': 3,\n",
    "#     'objective': 'l1',\n",
    "#     'random_state': 42,\n",
    "#     'extra_trees': True,\n",
    "#     'colsample_bytree': 0.95,\n",
    "#     'colsample_bynode': 0.95,\n",
    "#     'max_depth': 100,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'num_leaves': 10,\n",
    "#     'min_data_in_leaf': 10\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['active_lag1', 'active_lag2', 'active_lag3'],\n",
       " ['active_lag2', 'active_lag3', 'active_lag4'],\n",
       " ['active_lag3', 'active_lag4', 'active_lag5']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag=3\n",
    "list_cols_model = [[f'active_lag{lag_i+model_i+1}' for lag_i in range(lag)] for model_i in range(3)]\n",
    "list_cols_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n",
      "[LightGBM] [Warning] num_iterations is set=200, n_iter=200 will be ignored. Current value: num_iterations=200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=243, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=243\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'error_0': 1.8537019626124678,\n",
       "             'error_1': 2.4264903309547314,\n",
       "             'error_2': 2.8509509551177343})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dic_pipelines = {}\n",
    "y_test_preds  = [] \n",
    "\n",
    "y_val_preds = defaultdict(list)\n",
    "errors = defaultdict(list)\n",
    "\n",
    "\n",
    "for model_i in range(3):\n",
    "\n",
    "    train_y_i = train_y.iloc[:, model_i]\n",
    "    \n",
    "    cv_args = {\"test_size\": 1, \"n_splits\": n_SPLITS, \"train_size\": n_TRAIN_TRAIN_SIZE, 'gap_size': 0}\n",
    "    \n",
    "    cv = GroupTimeSeriesSplit(**cv_args)\n",
    "\n",
    "    # new_features = Pipeline([('select', SimpleFeatureEngineering(features=list_cols_model[model_i]))])\n",
    "    # print(list_cols_model[model_i])\n",
    "\n",
    "    raw_features = Pipeline([('select', tools.ColumnSelector(features=list_cols_model[model_i]))])\n",
    "    \n",
    "    merge_features_numeric = FeatureUnion([\n",
    "        # ('new_features', new_features),\n",
    "        ('raw_features', raw_features)\n",
    "    ])\n",
    "\n",
    "    final_features_numeric = Pipeline([\n",
    "                            ('merge_features',merge_features_numeric),\n",
    "                            # ('remove_outliers', Winsorizer(capping_method='iqr', tail='both',fold=1)),\n",
    "                            # ('standart_scaler', StandardScaler())\n",
    "                            ]\n",
    "                            )\n",
    "\n",
    "    \n",
    "    model = TransformedTargetRegressor(regressor=LGBMRegressor(**lgb_params))\n",
    "    \n",
    "    \n",
    "    model_pipeline = Pipeline([\n",
    "        (\"transform\", final_features_numeric),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    dic_pipelines[f'pipeline_model_{model_i}'] = model_pipeline\n",
    "    \n",
    "    param_grid = {}\n",
    "    grid = GridSearchCV(dic_pipelines[f'pipeline_model_{model_i}'], scoring=make_scorer(tools.SMAPE_1, greater_is_better=False), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(train_X, train_y_i, groups=train_X['dcount'])\n",
    "    \n",
    "    # print(grid.cv_results_)\n",
    "    # print(grid.best_estimator_)\n",
    "    \n",
    "    ## CHECK\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    check_train_period = TRAIN_DATES[-1-n_TRAIN_TRAIN_SIZE: -1] \n",
    "    validation_period = TRAIN_DATES[-1] \n",
    "    \n",
    "    best_model.fit(train_X.loc[check_train_period], train_y_i.loc[check_train_period])   \n",
    "    \n",
    "    y_val_pred =  best_model.predict(train_X.loc[validation_period])   \n",
    "    y_val_preds[f'target_{model_i}'] = y_val_pred\n",
    "    y_val_i = train_y_i.loc[validation_period]    \n",
    "    errors[f'error_{model_i}'] = tools.SMAPE_1(y_true=y_val_i, y_pred=y_val_pred)\n",
    "\n",
    "    # INFERENCE\n",
    "    # final_train_period = TRAIN_DATES[-n_TRAIN_TRAIN_SIZE:] \n",
    "\n",
    "    # best_model.fit(train_X.loc[final_train_period], train_y_i.loc[final_train_period])   \n",
    "\n",
    "    # y_test_pred =  best_model.predict(test_X.loc[TEST_DATES[model_i]] )\n",
    "    # y_test_preds.append(y_test_pred)\n",
    "\n",
    "# test_X['active'] = np.concatenate((y_test_preds))\n",
    "\n",
    "# prepare data for error analysis\n",
    "val_X = train_X.loc[validation_period]\n",
    "y_val_preds =  pd.DataFrame(y_val_preds, index=val_X.index)\n",
    "val_X = pd.concat((val_X, y_val_preds), axis=1)\n",
    "\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'error_0': 1.8537019626124678,\n",
       "             'error_1': 2.4264903309547314,\n",
       "             'error_2': 2.8509509551177343})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>56041_2022-12-01</td>\n",
       "      <td>56041</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>4.05</td>\n",
       "      <td>588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>56043_2022-11-01</td>\n",
       "      <td>56043</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>3.14</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>56043_2022-12-01</td>\n",
       "      <td>56043</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>56045_2022-11-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>1.79</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>56045_2022-12-01</td>\n",
       "      <td>56045</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>1.80</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128535 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                row_id  cfips           county    state first_day_of_month  microbusiness_density  active  is_test\n",
       "0      1001_2019-08-01   1001   Autauga County  Alabama         2019-08-01                   3.01    1249        0\n",
       "1      1001_2019-09-01   1001   Autauga County  Alabama         2019-09-01                   2.88    1198        0\n",
       "2      1001_2019-10-01   1001   Autauga County  Alabama         2019-10-01                   3.06    1269        0\n",
       "3      1001_2019-11-01   1001   Autauga County  Alabama         2019-11-01                   2.99    1243        0\n",
       "4      1001_2019-12-01   1001   Autauga County  Alabama         2019-12-01                   2.99    1243        0\n",
       "...                ...    ...              ...      ...                ...                    ...     ...      ...\n",
       "6265  56041_2022-12-01  56041     Uinta County  Wyoming         2022-12-01                   4.05     588        0\n",
       "6266  56043_2022-11-01  56043  Washakie County  Wyoming         2022-11-01                   3.14     190        0\n",
       "6267  56043_2022-12-01  56043  Washakie County  Wyoming         2022-12-01                   3.06     185        0\n",
       "6268  56045_2022-11-01  56045    Weston County  Wyoming         2022-11-01                   1.79     100        0\n",
       "6269  56045_2022-12-01  56045    Weston County  Wyoming         2022-12-01                   1.80     101        0\n",
       "\n",
       "[128535 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X['target_0'] = val_X['target_0'] * val_X['active_lag1']\n",
    "val_X['target_1'] = val_X['target_1'] * val_X['active_lag2']\n",
    "val_X['target_2'] = val_X['target_2'] * val_X['active_lag3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X['error_0']= val_X[['active_t0','target_0']].apply(lambda x: tools.SMAPE_1(x[[0]],x[[1]]),axis=1)\n",
    "val_X['error_1']= val_X[['active_t0','target_1']].apply(lambda x: tools.SMAPE_1(x[[0]],x[[1]]),axis=1)\n",
    "val_X['error_2']= val_X[['active_t0','target_2']].apply(lambda x: tools.SMAPE_1(x[[0]],x[[1]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = val_X.sort_values('error_0', ascending=False)\n",
    "# errors['cum_error'] = errors['error_0'].expanding().mean()\n",
    "# errors['cum_population'] = errors['population'].expanding().sum()\n",
    "# val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = errors[errors['error_0']>5].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_population</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(4.51, 6.793]</th>\n",
       "      <td>40.00</td>\n",
       "      <td>25.16</td>\n",
       "      <td>38.39</td>\n",
       "      <td>0.48</td>\n",
       "      <td>4.51</td>\n",
       "      <td>9.19</td>\n",
       "      <td>18.09</td>\n",
       "      <td>140.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(6.793, 9.064]</th>\n",
       "      <td>752.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.64</td>\n",
       "      <td>6.98</td>\n",
       "      <td>140.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(9.064, 11.335]</th>\n",
       "      <td>1782.00</td>\n",
       "      <td>4.52</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.02</td>\n",
       "      <td>5.78</td>\n",
       "      <td>126.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(11.335, 13.606]</th>\n",
       "      <td>517.00</td>\n",
       "      <td>6.47</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.95</td>\n",
       "      <td>8.83</td>\n",
       "      <td>37.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(13.606, 15.878]</th>\n",
       "      <td>44.00</td>\n",
       "      <td>25.66</td>\n",
       "      <td>31.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5.47</td>\n",
       "      <td>12.12</td>\n",
       "      <td>34.89</td>\n",
       "      <td>143.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count  mean   std  min  25%   50%   75%    max\n",
       "c_population                                                     \n",
       "(4.51, 6.793]      40.00 25.16 38.39 0.48 4.51  9.19 18.09 140.61\n",
       "(6.793, 9.064]    752.00  5.70  8.46 0.02 1.53  3.64  6.98 140.61\n",
       "(9.064, 11.335]  1782.00  4.52  6.62 0.00 1.22  3.02  5.78 126.80\n",
       "(11.335, 13.606]  517.00  6.47  5.91 0.01 2.36  4.95  8.83  37.48\n",
       "(13.606, 15.878]   44.00 25.66 31.31 0.10 5.47 12.12 34.89 143.23"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['c_population']=  pd.cut(np.log1p(errors['population']),5)\n",
    "errors['c_population'].value_counts()\n",
    "errors.groupby(['c_population'])['error_0'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = errors[errors['error_0']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter( np.log1p(errors['population']), np.log1p(errors['error_0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dcount</th>\n",
       "      <th>county_i</th>\n",
       "      <th>active_lag1</th>\n",
       "      <th>active_lag2</th>\n",
       "      <th>active_lag3</th>\n",
       "      <th>active_lag4</th>\n",
       "      <th>active_lag5</th>\n",
       "      <th>active_lag6</th>\n",
       "      <th>population</th>\n",
       "      <th>mdensity_t0</th>\n",
       "      <th>active_t0</th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>cfips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-01-01</th>\n",
       "      <th>01001</th>\n",
       "      <td>41</td>\n",
       "      <td>001</td>\n",
       "      <td>1475.00</td>\n",
       "      <td>1463.00</td>\n",
       "      <td>1472.00</td>\n",
       "      <td>1463.00</td>\n",
       "      <td>1455.00</td>\n",
       "      <td>1461.00</td>\n",
       "      <td>44438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>41</td>\n",
       "      <td>003</td>\n",
       "      <td>14133.00</td>\n",
       "      <td>14145.00</td>\n",
       "      <td>14320.00</td>\n",
       "      <td>14289.00</td>\n",
       "      <td>14545.00</td>\n",
       "      <td>14686.00</td>\n",
       "      <td>178105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>41</td>\n",
       "      <td>005</td>\n",
       "      <td>248.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>244.00</td>\n",
       "      <td>239.00</td>\n",
       "      <td>237.00</td>\n",
       "      <td>241.00</td>\n",
       "      <td>19995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01007</th>\n",
       "      <td>41</td>\n",
       "      <td>007</td>\n",
       "      <td>229.00</td>\n",
       "      <td>227.00</td>\n",
       "      <td>229.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>230.00</td>\n",
       "      <td>236.00</td>\n",
       "      <td>17800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01009</th>\n",
       "      <td>41</td>\n",
       "      <td>009</td>\n",
       "      <td>822.00</td>\n",
       "      <td>815.00</td>\n",
       "      <td>813.00</td>\n",
       "      <td>822.00</td>\n",
       "      <td>815.00</td>\n",
       "      <td>813.00</td>\n",
       "      <td>45201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-03-01</th>\n",
       "      <th>56037</th>\n",
       "      <td>43</td>\n",
       "      <td>037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>922.00</td>\n",
       "      <td>902.00</td>\n",
       "      <td>905.00</td>\n",
       "      <td>901.00</td>\n",
       "      <td>31514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>43</td>\n",
       "      <td>039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5043.00</td>\n",
       "      <td>5054.00</td>\n",
       "      <td>5035.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>19169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>43</td>\n",
       "      <td>041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>588.00</td>\n",
       "      <td>583.00</td>\n",
       "      <td>582.00</td>\n",
       "      <td>580.00</td>\n",
       "      <td>14641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>43</td>\n",
       "      <td>043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>194.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>43</td>\n",
       "      <td>045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9405 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dcount county_i  active_lag1  active_lag2  active_lag3  active_lag4  active_lag5  active_lag6  population  mdensity_t0  active_t0  microbusiness_density\n",
       "date       cfips                                                                                                                                                          \n",
       "2023-01-01 01001      41      001      1475.00      1463.00      1472.00      1463.00      1455.00      1461.00       44438          NaN        NaN                    NaN\n",
       "           01003      41      003     14133.00     14145.00     14320.00     14289.00     14545.00     14686.00      178105          NaN        NaN                    NaN\n",
       "           01005      41      005       248.00       247.00       244.00       239.00       237.00       241.00       19995          NaN        NaN                    NaN\n",
       "           01007      41      007       229.00       227.00       229.00       234.00       230.00       236.00       17800          NaN        NaN                    NaN\n",
       "           01009      41      009       822.00       815.00       813.00       822.00       815.00       813.00       45201          NaN        NaN                    NaN\n",
       "...                  ...      ...          ...          ...          ...          ...          ...          ...         ...          ...        ...                    ...\n",
       "2023-03-01 56037      43      037          NaN          NaN       922.00       902.00       905.00       901.00       31514          NaN        NaN                    NaN\n",
       "           56039      43      039          NaN          NaN      5043.00      5054.00      5035.00      5000.00       19169          NaN        NaN                    NaN\n",
       "           56041      43      041          NaN          NaN       588.00       583.00       582.00       580.00       14641          NaN        NaN                    NaN\n",
       "           56043      43      043          NaN          NaN       185.00       190.00       189.00       194.00        6000          NaN        NaN                    NaN\n",
       "           56045      43      045          NaN          NaN       101.00       100.00       100.00       100.00        5499          NaN        NaN                    NaN\n",
       "\n",
       "[9405 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_X['microbusiness_density'] = 100*test_X['active_t0']/test_X['population']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Prepare submission file\n",
    "\n",
    "# date_submission = '0303'\n",
    "# local_score = round(errors['error_0'],2)\n",
    "# model_name = 'regression_lag_1_4'\n",
    "\n",
    "# submission = tools.create_submission(test_X,date_submission, model_name, local_score, sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad1d413a8513d632047e434ee4038ec414e54bcf3dba008e5fb6dedaf37ce15f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
