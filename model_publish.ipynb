{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 10)\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data & Preliminary Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "old_train = pd.read_csv('./data/raw/godaddy-microbusiness-density-forecasting/train.csv')\n",
    "new_train = pd.read_csv('./data/raw/godaddy-microbusiness-density-forecasting_new/revealed_test.csv')\n",
    "old_test = pd.read_csv('./data/raw/godaddy-microbusiness-density-forecasting/test.csv')\n",
    "sample_submission = pd.read_csv('./data/raw/godaddy-microbusiness-density-forecasting/sample_submission.csv')\n",
    "\n",
    "train = pd.concat((old_train, new_train))\n",
    "test = old_test[~old_test['first_day_of_month'].isin(new_train['first_day_of_month'])]\n",
    "\n",
    "train['is_test'] = 0 ; test['is_test'] = 1\n",
    "\n",
    "data = pd.concat((\n",
    "        train,\n",
    "        test)\n",
    "        )\\\n",
    "    .reset_index(drop=True)\\\n",
    "    .assign(\n",
    "        cfips = lambda df: df['cfips'].astype(str).str.zfill(5),\n",
    "        date = lambda df: pd.to_datetime(df[\"first_day_of_month\"]),\n",
    "        )\\\n",
    "    .sort_values(['cfips','date'], ascending=True)\\\n",
    "    .assign(\n",
    "    \n",
    "        state_i = lambda df: df['cfips'].apply(lambda x: x[:2]),\n",
    "        county_i = lambda df: df['cfips'].apply(lambda x: x[2:]),        \n",
    "\n",
    "        year = lambda df: df['date'].dt.year,\n",
    "        date = lambda df: df[\"date\"].dt.date,\n",
    "\n",
    "        period = lambda df: df.groupby('cfips')['row_id'].cumcount(),\n",
    "\n",
    "        active_lag_1 = lambda df: df.groupby('cfips')['active'].shift(1),\n",
    "        active_lag_2 = lambda df: df.groupby('cfips')['active'].shift(2),\n",
    "        active_lag_3 = lambda df: df.groupby('cfips')['active'].shift(3),\n",
    "        active_lag_4 = lambda df: df.groupby('cfips')['active'].shift(4),\n",
    "\n",
    "        target_0 = lambda df: np.nan_to_num(df['active']/df.groupby('cfips')['active'].shift(1)-1, posinf=10),\n",
    "        target_1 = lambda df: np.nan_to_num(df['active']/df.groupby('cfips')['active'].shift(2)-1, posinf=10),\n",
    "        target_2 = lambda df: np.nan_to_num(df['active']/df.groupby('cfips')['active'].shift(3)-1, posinf=10),\n",
    "\n",
    "    )\\\n",
    "    .drop(['county','state'], axis='columns')\n",
    "    \n",
    "data.loc[data.is_test==1,['target_0','target_1','target_2']]  = np.nan\n",
    "\n",
    "assert all(data.groupby('cfips')['county_i'].nunique() == 1)\n",
    "assert all(data.groupby('cfips')['state_i'].nunique() == 1)\n",
    "assert data['cfips'].nunique() == 3135 # there are 3135 county,state tuples\n",
    "assert data['period'].nunique() == 47 # there are 47 series for each county state tuple\n",
    "assert data.query('is_test==0')['period'].nunique() == 41 # there are 41 series in the train set. \n",
    "assert data.query('is_test==1')['period'].nunique() == 6  # there are 6 series in the test set. \n",
    "\n",
    "# the puclic lb is updated as 01-2023\n",
    "# the private lb will include 03-2023, 04-2023, 05-2023\n",
    "# we dont care about 06-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>is_test</th>\n",
       "      <th>date</th>\n",
       "      <th>state_i</th>\n",
       "      <th>county_i</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>active_lag_1</th>\n",
       "      <th>active_lag_2</th>\n",
       "      <th>active_lag_3</th>\n",
       "      <th>active_lag_4</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1001_2022-09-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3.443</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2022</td>\n",
       "      <td>37</td>\n",
       "      <td>1455.000</td>\n",
       "      <td>1461.000</td>\n",
       "      <td>1422.000</td>\n",
       "      <td>1408.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1001_2022-10-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>3.464</td>\n",
       "      <td>1472.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2022</td>\n",
       "      <td>38</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1455.000</td>\n",
       "      <td>1461.000</td>\n",
       "      <td>1422.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122265</th>\n",
       "      <td>1001_2022-11-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>3.443</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2022</td>\n",
       "      <td>39</td>\n",
       "      <td>1472.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1455.000</td>\n",
       "      <td>1461.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122266</th>\n",
       "      <td>1001_2022-12-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>3.471</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2022</td>\n",
       "      <td>40</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1472.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1455.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128535</th>\n",
       "      <td>1001_2023-01-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>41</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1472.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131670</th>\n",
       "      <td>1001_2023-02-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>1472.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134805</th>\n",
       "      <td>1001_2023-03-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>1463.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137940</th>\n",
       "      <td>1001_2023-04-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141075</th>\n",
       "      <td>1001_2023-05-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144210</th>\n",
       "      <td>1001_2023-06-01</td>\n",
       "      <td>01001</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2023</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 row_id  \\\n",
       "37      1001_2022-09-01   \n",
       "38      1001_2022-10-01   \n",
       "122265  1001_2022-11-01   \n",
       "122266  1001_2022-12-01   \n",
       "128535  1001_2023-01-01   \n",
       "131670  1001_2023-02-01   \n",
       "134805  1001_2023-03-01   \n",
       "137940  1001_2023-04-01   \n",
       "141075  1001_2023-05-01   \n",
       "144210  1001_2023-06-01   \n",
       "\n",
       "        cfips  \\\n",
       "37      01001   \n",
       "38      01001   \n",
       "122265  01001   \n",
       "122266  01001   \n",
       "128535  01001   \n",
       "131670  01001   \n",
       "134805  01001   \n",
       "137940  01001   \n",
       "141075  01001   \n",
       "144210  01001   \n",
       "\n",
       "       first_day_of_month  \\\n",
       "37             2022-09-01   \n",
       "38             2022-10-01   \n",
       "122265         2022-11-01   \n",
       "122266         2022-12-01   \n",
       "128535         2023-01-01   \n",
       "131670         2023-02-01   \n",
       "134805         2023-03-01   \n",
       "137940         2023-04-01   \n",
       "141075         2023-05-01   \n",
       "144210         2023-06-01   \n",
       "\n",
       "        microbusiness_density  \\\n",
       "37                      3.443   \n",
       "38                      3.464   \n",
       "122265                  3.443   \n",
       "122266                  3.471   \n",
       "128535                    NaN   \n",
       "131670                    NaN   \n",
       "134805                    NaN   \n",
       "137940                    NaN   \n",
       "141075                    NaN   \n",
       "144210                    NaN   \n",
       "\n",
       "         active  \\\n",
       "37     1463.000   \n",
       "38     1472.000   \n",
       "122265 1463.000   \n",
       "122266 1475.000   \n",
       "128535      NaN   \n",
       "131670      NaN   \n",
       "134805      NaN   \n",
       "137940      NaN   \n",
       "141075      NaN   \n",
       "144210      NaN   \n",
       "\n",
       "        is_test  \\\n",
       "37            0   \n",
       "38            0   \n",
       "122265        0   \n",
       "122266        0   \n",
       "128535        1   \n",
       "131670        1   \n",
       "134805        1   \n",
       "137940        1   \n",
       "141075        1   \n",
       "144210        1   \n",
       "\n",
       "              date  \\\n",
       "37      2022-09-01   \n",
       "38      2022-10-01   \n",
       "122265  2022-11-01   \n",
       "122266  2022-12-01   \n",
       "128535  2023-01-01   \n",
       "131670  2023-02-01   \n",
       "134805  2023-03-01   \n",
       "137940  2023-04-01   \n",
       "141075  2023-05-01   \n",
       "144210  2023-06-01   \n",
       "\n",
       "       state_i  \\\n",
       "37          01   \n",
       "38          01   \n",
       "122265      01   \n",
       "122266      01   \n",
       "128535      01   \n",
       "131670      01   \n",
       "134805      01   \n",
       "137940      01   \n",
       "141075      01   \n",
       "144210      01   \n",
       "\n",
       "       county_i  \\\n",
       "37          001   \n",
       "38          001   \n",
       "122265      001   \n",
       "122266      001   \n",
       "128535      001   \n",
       "131670      001   \n",
       "134805      001   \n",
       "137940      001   \n",
       "141075      001   \n",
       "144210      001   \n",
       "\n",
       "        year  \\\n",
       "37      2022   \n",
       "38      2022   \n",
       "122265  2022   \n",
       "122266  2022   \n",
       "128535  2023   \n",
       "131670  2023   \n",
       "134805  2023   \n",
       "137940  2023   \n",
       "141075  2023   \n",
       "144210  2023   \n",
       "\n",
       "        period  \\\n",
       "37          37   \n",
       "38          38   \n",
       "122265      39   \n",
       "122266      40   \n",
       "128535      41   \n",
       "131670      42   \n",
       "134805      43   \n",
       "137940      44   \n",
       "141075      45   \n",
       "144210      46   \n",
       "\n",
       "        active_lag_1  \\\n",
       "37          1455.000   \n",
       "38          1463.000   \n",
       "122265      1472.000   \n",
       "122266      1463.000   \n",
       "128535      1475.000   \n",
       "131670           NaN   \n",
       "134805           NaN   \n",
       "137940           NaN   \n",
       "141075           NaN   \n",
       "144210           NaN   \n",
       "\n",
       "        active_lag_2  \\\n",
       "37          1461.000   \n",
       "38          1455.000   \n",
       "122265      1463.000   \n",
       "122266      1472.000   \n",
       "128535      1463.000   \n",
       "131670      1475.000   \n",
       "134805           NaN   \n",
       "137940           NaN   \n",
       "141075           NaN   \n",
       "144210           NaN   \n",
       "\n",
       "        active_lag_3  \\\n",
       "37          1422.000   \n",
       "38          1461.000   \n",
       "122265      1455.000   \n",
       "122266      1463.000   \n",
       "128535      1472.000   \n",
       "131670      1463.000   \n",
       "134805      1475.000   \n",
       "137940           NaN   \n",
       "141075           NaN   \n",
       "144210           NaN   \n",
       "\n",
       "        active_lag_4  \\\n",
       "37          1408.000   \n",
       "38          1422.000   \n",
       "122265      1461.000   \n",
       "122266      1455.000   \n",
       "128535      1463.000   \n",
       "131670      1472.000   \n",
       "134805      1463.000   \n",
       "137940      1475.000   \n",
       "141075           NaN   \n",
       "144210           NaN   \n",
       "\n",
       "        target_0  \\\n",
       "37         0.005   \n",
       "38         0.006   \n",
       "122265    -0.006   \n",
       "122266     0.008   \n",
       "128535       NaN   \n",
       "131670       NaN   \n",
       "134805       NaN   \n",
       "137940       NaN   \n",
       "141075       NaN   \n",
       "144210       NaN   \n",
       "\n",
       "        target_1  \\\n",
       "37         0.001   \n",
       "38         0.012   \n",
       "122265     0.000   \n",
       "122266     0.002   \n",
       "128535       NaN   \n",
       "131670       NaN   \n",
       "134805       NaN   \n",
       "137940       NaN   \n",
       "141075       NaN   \n",
       "144210       NaN   \n",
       "\n",
       "        target_2  \n",
       "37         0.029  \n",
       "38         0.008  \n",
       "122265     0.005  \n",
       "122266     0.008  \n",
       "128535       NaN  \n",
       "131670       NaN  \n",
       "134805       NaN  \n",
       "137940       NaN  \n",
       "141075       NaN  \n",
       "144210       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query(\"cfips == '01001'\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding census data\n",
    "data_census = []\n",
    "for year in range(2017,2022):\n",
    "    COLS = ['GEO_ID','NAME','S0101_C01_026E']\n",
    "    data_census_i = pd.read_csv(f'./data/raw/census_data_1/ACSST5Y{year}.S0101-Data.csv',usecols=COLS)\n",
    "    data_census_i = data_census_i.iloc[1:]\n",
    "    data_census_i['population'] = data_census_i['S0101_C01_026E'].astype('int')\n",
    "\n",
    "\n",
    "    data_census_i['cfips'] = data_census_i.GEO_ID.apply(lambda x: f\"{int(x.split('US')[-1]):05}\" )\n",
    "    data_census_i['year'] = year+2\n",
    "    data_census.append(data_census_i[['cfips','year','population']])\n",
    "\n",
    "data_census = pd.concat((data_census),axis='rows')\n",
    "data = data.merge(data_census, on=['cfips','year'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for cv\n",
    "n_SPLITS = 5 \n",
    "n_TRAIN_TRAIN_SIZE = 6\n",
    "n_TRAIN_PERIOD = n_TRAIN_TRAIN_SIZE + 3 + n_SPLITS - 1 \n",
    "\n",
    "# parameters used for filtering/selecting data\n",
    "TEST_DATES = list(np.sort(data.query('is_test==1')['date'].unique())[:3])\n",
    "TEST_PERIOD = list(np.sort(data.query('is_test==1')['period'].unique())[:3])\n",
    "\n",
    "TRAIN_PERIOD = list(np.sort(data.query('is_test==0')['period'].unique())[-n_TRAIN_PERIOD:])\n",
    "TRAIN_DATES = list(np.sort(data.query('is_test==0')['date'].unique())[-n_TRAIN_PERIOD:])\n",
    "\n",
    "# some parameters which we will use for feature engineering\n",
    "LEAKAGE = ['microbusiness_density','active']\n",
    "TARGETS = ['target_0', 'target_1', 'target_2']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we sample the data since there is no need to use all the data for training according to our cv parameters\n",
    "# also we prepare the lag values here since later we will devide the train/test data to avoid any leakage during the feature engineering\n",
    "\n",
    "sample = data.copy()\n",
    "sample = sample.sort_values(['cfips','date'])\n",
    "\n",
    "LAGS = 4\n",
    "for i in range(1, LAGS+1):\n",
    "    lag_col = f'target_lag{i}'\n",
    "    sample[lag_col] = sample.groupby('cfips')[TARGETS[0]].shift(i)  \n",
    "\n",
    "# need to sort values by period for GroupTimeSeriesSplit\n",
    "sample = sample.sort_values('period')\n",
    "\n",
    "sample_train= sample.query(\"period in @TRAIN_PERIOD\") ; sample_test= sample.query(\"period in @TEST_PERIOD\")\n",
    "train_X = sample_train.drop(TARGETS,axis='columns') ; train_y = sample_train[TARGETS]\n",
    "test_X = sample_test.drop(TARGETS,axis='columns') ; test_y = sample_test[TARGETS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "from sklearn.metrics import make_scorer\n",
    "from mlxtend.evaluate.time_series import GroupTimeSeriesSplit\n",
    "from collections import defaultdict\n",
    "\n",
    "def SMAPE (y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select only specified columns\"\"\"\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "    \n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Make some feature engineering on selected columns\"\"\"\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\t    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        new_features = []\n",
    "        return X_transformed[new_features]\n",
    "    \n",
    "\n",
    "\n",
    "lag=2\n",
    "list_lag_values = [[f'target_lag{lag_i+model_i+1}' for lag_i in range(lag)] for model_i in range(3)]\n",
    "\n",
    "dic_pipelines = {}\n",
    "y_test_preds  = [] \n",
    "y_validation_preds = defaultdict(list)\n",
    "validation_scores = defaultdict(list)\n",
    "\n",
    "\n",
    "for model_i in range(3):\n",
    "    # chose the right target to model \n",
    "    train_y_i = train_y.iloc[:, model_i]\n",
    "    \n",
    "    # raw features without extra feature engineering\n",
    "    raw_features = Pipeline([('select features', ColumnSelector(features=list_lag_values[model_i]))])\n",
    "    # features after some transformation (in this case there is no transformed feature)\n",
    "    new_features = Pipeline([('engineer selected features', FeatureEngineering(features=[]))])\n",
    "     \n",
    "    merge_features = FeatureUnion([\n",
    "        ('raw_features', raw_features),\n",
    "        ('new_features', new_features)\n",
    "    ])\n",
    "\n",
    "    # last transformation to all numeric features such as removing outliers (here no transformation is made)\n",
    "    numeric_features = Pipeline([\n",
    "                            ('merge_features',merge_features),\n",
    "                            # ('remove_outliers', Winsorizer()),\n",
    "                            # ('standart_scaler', StandardScaler())\n",
    "                            ]\n",
    "                            )\n",
    "    # other type of transformations can be made to different type of fields such as categorical features and added to the pipeline later\n",
    "    # categrical_features = Pipeline([])\n",
    "\n",
    "    # transformedTargetRegressor helps to make target transformation such as log within the pipeline\n",
    "    model = TransformedTargetRegressor()  \n",
    "    \n",
    "    # model pipeline = feature + model \n",
    "    model_pipeline = Pipeline([\n",
    "        (\"transform_numeric\", numeric_features),\n",
    "        # (\"transform_categorical\", categorical_features),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # parameters to tune the model should be added here\n",
    "    # param_grid = {'model__regressor':[LinearRegression(),LinearSVR()]}\n",
    "    param_grid = {'model__regressor':[LinearRegression()]}\n",
    "    \n",
    "    cv_args = {\"test_size\": 1, \"n_splits\": n_SPLITS, \"train_size\": n_TRAIN_TRAIN_SIZE, 'gap_size': 0}\n",
    "    cv = GroupTimeSeriesSplit(**cv_args)\n",
    "    \n",
    "    grid = GridSearchCV(model_pipeline, scoring=make_scorer(SMAPE, greater_is_better=False), param_grid=param_grid, cv=cv)\n",
    "    \n",
    "    grid.fit(train_X, train_y_i, groups=train_X['period'])\n",
    "    \n",
    "    # pipeline can be persisted at a dictionary\n",
    "    dic_pipelines[f'pipeline_model_{model_i}'] = grid\n",
    "\n",
    "    # Validation Scores\n",
    "    # since we use the ratio of active's as the target value the error metric is not comparable to what the competition calculates\n",
    "    # so here we calculate the validation score for the selected model by using absolute values of active\n",
    "    # the error should be used to sleect which model to use as final submission\n",
    "    # otherwise there is a risk of overfitting\n",
    "    # we also store these values to make further error analysis\n",
    "\n",
    "    train_period = TRAIN_PERIOD[-1-n_TRAIN_TRAIN_SIZE: -1] \n",
    "    validation_period = [TRAIN_PERIOD[-1]]\n",
    "    train_index = train_X.query('period in @train_period').index\n",
    "    val_index = train_X.query('period in @validation_period').index\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_model.fit(train_X.loc[train_index], train_y_i.loc[train_index])  \n",
    "    \n",
    "    y_val_pred =  (best_model.predict(train_X.loc[val_index])+1)*train_X.loc[val_index,f'active_lag_{model_i+1}']\t\n",
    "    y_validation_preds[f'target_{model_i}'] = y_val_pred\n",
    "    \n",
    "    validation_scores[f'error_{model_i}'] = SMAPE(y_true= train_X.loc[val_index,'active'], y_pred=y_val_pred)\n",
    "\n",
    "    # Inference\n",
    "    inference_train_period = TRAIN_PERIOD[-n_TRAIN_TRAIN_SIZE:] \n",
    "    inference_test_period_i = [TEST_PERIOD[model_i]]\n",
    "    inference_train_index = train_X.query('period in @inference_train_period').index\n",
    "\n",
    "    best_model.fit(train_X.loc[inference_train_index], train_y_i.loc[inference_train_index])\n",
    "    y_test_preds.append(best_model.predict(test_X.query('period in @inference_test_period_i')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transform_numeric&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;merge_features&#x27;,\n",
       "                                  FeatureUnion(transformer_list=[(&#x27;raw_features&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;select &#x27;\n",
       "                                                                                   &#x27;features&#x27;,\n",
       "                                                                                   ColumnSelector(features=[&#x27;target_lag1&#x27;,\n",
       "                                                                                                            &#x27;target_lag2&#x27;]))])),\n",
       "                                                                 (&#x27;new_features&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;engineer &#x27;\n",
       "                                                                                   &#x27;selected &#x27;\n",
       "                                                                                   &#x27;features&#x27;,\n",
       "                                                                                   FeatureEngineering(features=[]))]))]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TransformedTargetRegressor(regressor=LinearRegression()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transform_numeric&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;merge_features&#x27;,\n",
       "                                  FeatureUnion(transformer_list=[(&#x27;raw_features&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;select &#x27;\n",
       "                                                                                   &#x27;features&#x27;,\n",
       "                                                                                   ColumnSelector(features=[&#x27;target_lag1&#x27;,\n",
       "                                                                                                            &#x27;target_lag2&#x27;]))])),\n",
       "                                                                 (&#x27;new_features&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;engineer &#x27;\n",
       "                                                                                   &#x27;selected &#x27;\n",
       "                                                                                   &#x27;features&#x27;,\n",
       "                                                                                   FeatureEngineering(features=[]))]))]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TransformedTargetRegressor(regressor=LinearRegression()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transform_numeric: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;merge_features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;raw_features&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;select &#x27;\n",
       "                                                                  &#x27;features&#x27;,\n",
       "                                                                  ColumnSelector(features=[&#x27;target_lag1&#x27;,\n",
       "                                                                                           &#x27;target_lag2&#x27;]))])),\n",
       "                                                (&#x27;new_features&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;engineer &#x27;\n",
       "                                                                  &#x27;selected &#x27;\n",
       "                                                                  &#x27;features&#x27;,\n",
       "                                                                  FeatureEngineering(features=[]))]))]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">merge_features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;raw_features&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;select features&#x27;,\n",
       "                                                 ColumnSelector(features=[&#x27;target_lag1&#x27;,\n",
       "                                                                          &#x27;target_lag2&#x27;]))])),\n",
       "                               (&#x27;new_features&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;engineer selected features&#x27;,\n",
       "                                                 FeatureEngineering(features=[]))]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>raw_features</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnSelector(features=[&#x27;target_lag1&#x27;, &#x27;target_lag2&#x27;])</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>new_features</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureEngineering</label><div class=\"sk-toggleable__content\"><pre>FeatureEngineering(features=[])</pre></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: TransformedTargetRegressor</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetRegressor(regressor=LinearRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">regressor: LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transform_numeric',\n",
       "                 Pipeline(steps=[('merge_features',\n",
       "                                  FeatureUnion(transformer_list=[('raw_features',\n",
       "                                                                  Pipeline(steps=[('select '\n",
       "                                                                                   'features',\n",
       "                                                                                   ColumnSelector(features=['target_lag1',\n",
       "                                                                                                            'target_lag2']))])),\n",
       "                                                                 ('new_features',\n",
       "                                                                  Pipeline(steps=[('engineer '\n",
       "                                                                                   'selected '\n",
       "                                                                                   'features',\n",
       "                                                                                   FeatureEngineering(features=[]))]))]))])),\n",
       "                ('model',\n",
       "                 TransformedTargetRegressor(regressor=LinearRegression()))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see some details about the pipelines that we used to model\n",
    "dic_pipelines['pipeline_model_0'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'error_0': 1.8583042562020717,\n",
       "             'error_1': 2.4796749903226614,\n",
       "             'error_2': 2.9173206825002134})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prepare validation for error analysis\n",
    "# val_X = train_X.query('dcount in @check_validation_period')\n",
    "# y_val_preds =  pd.DataFrame(y_validation_preds, index=val_X.index)\n",
    "# val_X = pd.concat((val_X, y_val_preds), axis=1)\n",
    "\n",
    "# this is the validation score which we use to have a feeling about the model performance on the test set\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start to prepare the predictions for submission\n",
    "test_X['ratio_pred'] = np.concatenate((y_test_preds))\n",
    "\n",
    "for i,TEST_PERIOD_i in enumerate(TEST_PERIOD):\n",
    "    test_index = test_X.query('period == @TEST_PERIOD_i').index \n",
    "    test_X.loc[test_index,'pred'] = (test_X.loc[test_index]['ratio_pred']+1)*test_X.loc[test_index][f'active_lag_{i+1}']\n",
    "\n",
    "# we replace the predictions for low populated zones with their lag values (benchmark values). \n",
    "# the rule for population is lower than .3 quantile\n",
    "test_X['final_pred'] = test_X['pred']\n",
    "condition = test_X['population']<np.quantile(test_X['population'],q=.3)\n",
    "\n",
    "# we can change the rule for the benchmark values such as mean of last 2 lag values etc\n",
    "test_X = test_X.sort_values(['cfips','first_day_of_month'])\n",
    "test_X['benchmark'] = test_X.groupby('cfips').first()[['active_lag_1','active_lag_1','active_lag_1']].stack().values\n",
    "\n",
    "test_X.loc[condition,'final_pred'] = test_X.loc[condition,'benchmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the submission file\n",
    "\n",
    "\n",
    "date_submission = '1003'\n",
    "local_score = round(validation_scores['error_0'],2)\n",
    "model_name = 'ratio_regression_lag_1_2_with_.3_constant'\n",
    "\n",
    "df_output = test_X.assign(\n",
    "    microbusiness_density = lambda df: 100 * df['final_pred'] / df['population'],\n",
    "    row_id = lambda df: df.apply(lambda df: \"{}_{}\".format(int(df['cfips']),df['date']), axis='columns'))[['row_id','microbusiness_density']]\n",
    "\n",
    "submission = pd.concat((\n",
    "    df_output,\n",
    "    sample_submission[~sample_submission.row_id.isin(df_output.row_id)]))\n",
    "\n",
    "# submission.to_csv(f\"data/{date_submission}_{model_name}_local_{local_score}.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>microbusiness_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1001_2023-01-01</td>\n",
       "      <td>3.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1001_2023-02-01</td>\n",
       "      <td>3.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1001_2023-03-01</td>\n",
       "      <td>3.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1003_2023-01-01</td>\n",
       "      <td>7.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1003_2023-02-01</td>\n",
       "      <td>8.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>56037_2023-06-01</td>\n",
       "      <td>3.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25076</th>\n",
       "      <td>56039_2023-06-01</td>\n",
       "      <td>3.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25077</th>\n",
       "      <td>56041_2023-06-01</td>\n",
       "      <td>3.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25078</th>\n",
       "      <td>56043_2023-06-01</td>\n",
       "      <td>3.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25079</th>\n",
       "      <td>56045_2023-06-01</td>\n",
       "      <td>3.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 row_id  \\\n",
       "41      1001_2023-01-01   \n",
       "42      1001_2023-02-01   \n",
       "43      1001_2023-03-01   \n",
       "88      1003_2023-01-01   \n",
       "89      1003_2023-02-01   \n",
       "...                 ...   \n",
       "25075  56037_2023-06-01   \n",
       "25076  56039_2023-06-01   \n",
       "25077  56041_2023-06-01   \n",
       "25078  56043_2023-06-01   \n",
       "25079  56045_2023-06-01   \n",
       "\n",
       "       microbusiness_density  \n",
       "41                     3.343  \n",
       "42                     3.358  \n",
       "43                     3.370  \n",
       "88                     7.994  \n",
       "89                     8.035  \n",
       "...                      ...  \n",
       "25075                  3.818  \n",
       "25076                  3.818  \n",
       "25077                  3.818  \n",
       "25078                  3.818  \n",
       "25079                  3.818  \n",
       "\n",
       "[25080 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad1d413a8513d632047e434ee4038ec414e54bcf3dba008e5fb6dedaf37ce15f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
